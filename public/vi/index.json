[
{
	"uri": "https://ntvinh04.github.io/blog-trans/vi/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Cách tạo Agent với LlamaIndex 📖 Bài viết gốc: How to create agents with LlamaIndex\n👤 Tác giả: Axel Sirota - Microsoft Certified Trainer\n📅 Ngày xuất bản: 14/08/2025\n🌐 Nguồn: pluralsight\n👨‍💻 Người dịch: Ngô Thành Vinh - FCJ Intern\n📅 Ngày dịch: 19/08/2025\n⏱️ Thời gian đọc: 9 phút\n📋 Tóm tắt Bài viết hướng dẫn cách xây dựng một Knowledge Retrieval Agent - một Agent có khả năng truy xuất thông tin từ các tập dữ liệu bên ngoài và đưa ra câu trả lời phù hợp. Để làm điều này, tác giả giới thiệu về LlamaIndex – công cụ giúp kết nối ngôn ngữ lớn và dữ liệu ngoài bằng cách sử dụng chỉ mục (index) để truy vấn hiệu quả. Bài viết hướng dẫn từng bước từ việc cài đặt môi trường, chuẩn bị dữ liệu, xây dựng index, truy vấn thông tin, tới cải thiện kết quả bằng Hugging Face, và kết nối với AWS S3 hay Azure Blob Storage. Và cuối cùng là các trường hợp sử dụng thực tiễn và lưu ý tối ưu hóa khi triển khai.\n🎯 Đối tượng đọc: Developer/AI Engineer trình độ Intermediate muốn triển khai Agent có tính ứng dụng cao\n📊 Độ khó: Intermediate\n🏷️ Tags: LlamaIndex, Agent, Knowledge Retrieval\n📚 Mục lục Phần 1: Giới thiệu Phần 2: Agent là gì, và tại sao lại sử dụng LlamaIndex Phần 3: Xây dựng Agent truy xuất thông tin Phần 4: Kết hợp với dữ liệu từ AWS S3 hoặc Azure Blob Storage Phần 5: Nên chọn phương pháp nào Phần 6: Ứng dụng thực tế Phần 7: Xử lý lỗi thường gặp và mẹo tối ưu Phần 8: Kết luận Glossary - Thuật ngữ Tài liệu tham khảo Phần 1: Giới thiệu Ngày nay trí tuệ nhân tạo (AI) đang định hình lại cách chúng ta sử dụng công nghệ và một trong những ứng dụng tiêu biểu là tạo ra các Agent thông minh. Các Agent này hoạt động tự động với khả năng trả lời câu hỏi, tìm kiếm thông tin và thậm chí là đưa ra quyết định. Ở trong bài viết này chúng ta sẽ đi sâu vào cách để tạo ra một Agent có khả năng truy xuất thông tin bằng LlamaIndex\nNếu bạn là một người đam mê AI với trình độ Intermediate và đã sẵn sàng để tạo ra một Agent. Đến cuối bài viết này, bạn không chỉ hiểu được các khái niệm đằng sau llamaindex mà bạn còn có được một Agent có thể truy xuất thông tin mà bạn có thể triển khai được\nPhần 2: Agent là gì, và tại sao lại sử dụng LlamaIndex Bạn hãy tưởng tượng ra một người thủ thư ảo, người mà có thể tìm kiếm thông tin trong hàng ngàn cuốn sách và đưa cho bạn thông tin về thứ bạn đang tìm. Đó chính xác là những gì Agent thực hiện. Nó sẽ tự động quản lý các nhiệm vụ, tìm kiếm thông tin và tương tác với người dùng để đưa ra kết quả\nNhưng vấn đề bây giờ là làm sao để cung cấp quyền hạn cho người thủ thư này quyền được truy cập vào các tài liệu văn bản, cơ sở dữ liệu và các bài viết? Đây chính là lúc mà chúng ta sử dụng LlamaIndex\nLlamaIndex cầu nối giữa dữ liệu và ngôn ngữ lớn LlamaIndex (hay trước đây còn gọi là GPT Index) đã đơn giản hóa quá trình tích hợp ngôn ngữ lớn như OpenAI GPT-4 với các dữ liệu bên ngoài một cách hiệu quả. Thay vì làm quá tải mô hình với lượng lớn dữ liệu đầu vào thì LlamaIndex cho phép AI truy vấn một chỉ mục đã được xây dựng sẵn dựa trên dữ liệu đã có, giúp các phản hồi nhanh và chính xác hơn\nCác lợi ích bao gồm Truy xuất thông tin từ loại dữ liệu có cấu trúc (ví dụ: table trong sql) và dữ liệu không có cấu trúc (ví dụ: văn bản) Tương thích với OpenAI API và Hugging Face Transformers Dễ triển khai để xây dựng Agent Phần 3: Xây dựng Agent truy xuất thông tin Bây giờ chúng ta sẽ đi từng bước để xây dựng một Agent có thể truy xuất tri thức từ dữ liệu tùy chính của bạn\nBước 1: Cài đặt mỗi trường Trước tiên cần phải tải các công cụ cần thiết bao gồm LlamaIndex, OpenAI’s API, and Hugging Face Transformers\npip install llama-index openai transformers Bên cạnh đó bạn cũng cần OpenAI API Key. Nếu bạn chưa có đăng ký tại OpenAI và lưu trữ API Key của bạn. Ở trong code của bạn thêm vào đoạn code sau:\nimport os\r# Nhập OpenAI API key của bạn ở đây\ros.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;your-openai-api-key\u0026#34; Bước 2: Chuẩn bị dữ liệu của bạn Agent của bạn cần một dữ liệu gì đó để truy vấn vậy nên bạn cần chuẩn bị một bộ dữ liệu hoặc một bộ sưu tập các tài liệu văn bản hoặc bài viết mà Agent của bạn cần tìm kiếm\nCho ví dụ này, lưu trữ tệp văn bản vào thư mục có tên data/ . Sau đó dùng LlamaIndex gọi SimpleDirectoryReader để tải tài liệu vào chương trình\nfrom llama_index import SimpleDirectoryReader\r# Tải tài liệu từ thư mục data\rdocuments = SimpleDirectoryReader(\u0026#39;./data\u0026#39;).load_data()\rprint(f\u0026#34;Loaded {len(documents)} documents!\u0026#34;) Nếu bạn không có tài liệu mẫu, thì nên tạo một vài file .txt với chủ đề như ứng dụng của Agent hoặc lợi ích của công nghệ. Điều này sẽ cung cấp cho Agent của bạn một cái gì đó để truy vấn\nBước 3: Tạo chỉ mục Một chỉ mục giống như bản đồ tối ưu cho việc tìm kiếm dữ liệu của bạn. LlamaIndex cung cấp các loại chỉ mục khác nhau, chẳng hạn như chỉ mục dựa trên vector hoặc dựa trên từ khóa. Để đơn giản thì chúng ta sẽ tạo một chỉ mục dựa trên vector để tìm kiếm các đoạn văn bản tương tự\nfrom llama_index import GPTVectorStoreIndex\r# Xây dựng chỉ mục dựa vào tài liệu được tải lên\rindex = GPTVectorStoreIndex.from_documents(documents)\r# Lưu lại chỉ mục để sử dụng sau\rindex.storage_context.persist(\u0026#39;./index_storage\u0026#39;) Và đây là những gì diễn ra:\nGPTVectorStoreIndex chuyển đổi dữ liệu của bạn thành các biểu diễn vector giúp việc tìm kiếm dễ dàng hơn persist() sẽ lưu chỉ mục xuống ổ đĩa và bạn có thể sử dụng sau này Bước 4: Truy vấn chỉ mục Bây giờ chỉ mục đã sẵn sàng và truy vấn nó. Tiếp theo chúng ta sẽ tích hợp OpenAI API để xử lý truy vấn và trả lời\n# Truy vấn chỉ mục\rdef query_index(query: str, index):\rresponse = index.query(query)\rreturn response.response\r# Truy vấn mẫu\rquery = \u0026#34;What are the benefits of AI in healthcare?\u0026#34;\rresponse = query_index(query, index)\rprint(\u0026#34;Agent Response:\u0026#34;, response) Đây là một hàm đơn giản để nhận một truy vấn từ người dùng, đưa truy vấn qua chỉ mục và trả về phản hồi có liên quan nhất\nBước 5: Kết hợp Hugging Face để cải thiện câu trả lời Trong khi các mô hình OpenAI thường rất tốt trong việc hiểu các truy vấn, bạn có thể sử dụng Hugging Face Transformers để tinh chỉnh các phản hồi. Chẳng hạn bạn có thể sử dụng mô hình tóm tắt để giảm bớt các câu trả lời dài dòng\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r# Tải một mô hình Hugging Face\rtokenizer = AutoTokenizer.from_pretrained(\u0026#34;t5-large\u0026#34;)\rmodel = AutoModelForSeq2SeqLM.from_pretrained(\u0026#34;t5-large\u0026#34;)\r# Tinh chỉnh phản hồi\rdef refine_response(query, raw_response):\rinputs = tokenizer(query + raw_response, return_tensors=\u0026#34;pt\u0026#34;, truncation=True)\routputs = model.generate(**inputs, max_length=50)\rreturn tokenizer.decode(outputs[0], skip_special_tokens=True)\r# Tinh chỉnh phản hồi của Agent\rrefined_response = refine_response(query, response)\rprint(\u0026#34;Refined Response:\u0026#34;, refined_response) Ở trong ví dụ này:\nMô hình T5-large của Hugging Face tinh chỉnh phản hồi thô bằng cách tóm tắt hoặc diễn đạt lại Bước này giúp cải thiện chất lượng câu trả lời, đặc biệt đối với dữ liệu dài dòng hoặc không có cấu trúc Phần 4: Kết hợp với dữ liệu từ AWS S3 hoặc Azure Blob Storage Trong môi trường triển khai, các tệp dữ liệu thường nằm trên dịch vụ lưu trữ đám mây như AWS S3 hoặc Azure Blob Storage thay vì lưu trong file cục bộ LlamaIndex cung cấp nhiều cách để làm việc với các hệ thống lưu trữ đám mây này, đảm bảo tính linh hoạt cho từng trường hợp sử dụng khác nhau. Bạn có thể chọn giữa\nTải thủ công: Tải file từ lưu trữ đám mây về và xử lý trên máy cục bộ. Tích hợp trực tiếp với AWS S3: Sử dụng class SimpleS3Reader của LlamaIndex để truy cập liền mạch vào bucket S3. Tích hợp trực tiếp với Azure Blob Storage: Sử dụng SimpleBlobReader để tải dữ liệu trực tiếp từ container của Azure Blob. Bây giờ chúng ta sẽ tìm hiểu chi tiết từng lựa chọn Trường hợp 1: Tải file về và xử lý thủ công AWS S3: Tải thủ công Chúng ta sẽ sử dụng thư viện boto3 để lấy file từ bucket của S3 và lưu cục bộ, và tải dữ liệu bằng SimpleDirectoryReader\nimport boto3\rfrom llama_index import SimpleDirectoryReader\rimport os\r# Cấu hình AWS S3\rAWS_ACCESS_KEY = \u0026#34;your-aws-access-key\u0026#34;\rAWS_SECRET_KEY = \u0026#34;your-aws-secret-key\u0026#34;\rAWS_BUCKET_NAME = \u0026#34;your-s3-bucket-name\u0026#34;\rLOCAL_DOWNLOAD_PATH = \u0026#34;./s3_data/\u0026#34;\r# Khởi tạo S3\rs3_client = boto3.client(\r\u0026#39;s3\u0026#39;,\raws_access_key_id=AWS_ACCESS_KEY,\raws_secret_access_key=AWS_SECRET_KEY\r)\r# Tải tất cả file từ S3 bucket\rdef download_s3_bucket(bucket_name, local_path):\ros.makedirs(local_path, exist_ok=True)\rresponse = s3_client.list_objects_v2(Bucket=bucket_name)\rfor obj in response.get(\u0026#39;Contents\u0026#39;, []):\rs3_client.download_file(bucket_name, obj[\u0026#39;Key\u0026#39;], os.path.join(local_path, obj[\u0026#39;Key\u0026#39;]))\rprint(f\u0026#34;Downloaded: {obj[\u0026#39;Key\u0026#39;]}\u0026#34;)\r# Tải và nạp vào LlamaIndex\rdownload_s3_bucket(AWS_BUCKET_NAME, LOCAL_DOWNLOAD_PATH)\rdocuments = SimpleDirectoryReader(LOCAL_DOWNLOAD_PATH).load_data()\rprint(f\u0026#34;Loaded {len(documents)} documents from S3!\u0026#34;) Azure Blob Storage: Tải thủ công Đối với Azure Blob Storage, chúng ta sử dụng thư viện azure-storage-blob theo cách tương tự như tìm và lưu vào file cục bộ\nfrom azure.storage.blob import BlobServiceClient\rfrom llama_index import SimpleDirectoryReader\rimport os\r# Cấu hình Azure Blob Storage\rAZURE_CONNECTION_STRING = \u0026#34;your-azure-connection-string\u0026#34;\rAZURE_CONTAINER_NAME = \u0026#34;your-container-name\u0026#34;\rLOCAL_DOWNLOAD_PATH = \u0026#34;./azure_blob_data/\u0026#34;\r# Khởi tạo BlobServiceClient\rblob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\rcontainer_client = blob_service_client.get_container_client(AZURE_CONTAINER_NAME)\r# Tải toàn bộ blobs từ Azure container\rdef download_azure_container(container_client, local_path):\ros.makedirs(local_path, exist_ok=True)\rblob_list = container_client.list_blobs()\rfor blob in blob_list:\rblob_client = container_client.get_blob_client(blob)\rwith open(os.path.join(local_path, blob.name), \u0026#34;wb\u0026#34;) as file:\rfile.write(blob_client.download_blob().readall())\rprint(f\u0026#34;Downloaded: {blob.name}\u0026#34;)\r# Tải files và nạp vào LlamaIndex\rdownload_azure_container(container_client, LOCAL_DOWNLOAD_PATH)\rdocuments = SimpleDirectoryReader(LOCAL_DOWNLOAD_PATH).load_data()\rprint(f\u0026#34;Loaded {len(documents)} documents from Azure Blob Storage!\u0026#34;) Trường hợp 2: Tích hợp trực tiếp AWS S3 bằng SimpleS3Reader Nếu bạn muốn tiếp cận một cách tiếp cận gọn gàng hơn, LlamaIndex cung cấp class SimpleS3Reader để tích hợp trực tiếp với AWS S3. Class này sẽ tự động xử lý việc xác thực, truy xuất và phân tích dữ liệu ngầm ở sau\nCode mẫu: sử dụng SimpleS3Reader from llama_index import SimpleS3Reader\r# Cấu hình AWS S3\rAWS_ACCESS_KEY = \u0026#34;your-aws-access-key\u0026#34;\rAWS_SECRET_KEY = \u0026#34;your-aws-secret-key\u0026#34;\rAWS_BUCKET_NAME = \u0026#34;your-s3-bucket-name\u0026#34;\r# Khởi tạo S3 reader\rs3_reader = SimpleS3Reader(\rbucket=AWS_BUCKET_NAME,\raws_access_key_id=AWS_ACCESS_KEY,\raws_secret_access_key=AWS_SECRET_KEY,\r)\r# Tải tài liệu trực tiếp từ S3\rdocuments = s3_reader.load_data()\rprint(f\u0026#34;Loaded {len(documents)} documents from S3!\u0026#34;) Cách hoạt động Xác thực: SimpleS3Reader sử dụng AWS access key và secret key của bạn để xác thực với S3 bucket Phân tích file: SimpleS3Reader lấy và xử lý tài liệu trực tiếp từ bucket mà không cần lưu vào bộ nhớ cục bộ Tương thích với LlamaIndex: Tài liệu được nạp vào định dạng nội bộ của LlamaIndex, sẵn sàng cho việc lập chỉ mục và truy vấn Trường hợp 3: Tích hợp trực tiếp Azure Blob Storage bằng SimpleBlobReader Đối với Azure Blob Storage, LlamaIndex cung cấp class SimpleBlobReader giúp đơn giản hóa việc truy cập và tải dữ liệu từ Azure containers\nCode mẫu: sử dụng SimpleBlobReader from llama_index import SimpleBlobReader\r# Cấu hình Azure Blob Storage\rAZURE_CONNECTION_STRING = \u0026#34;your-azure-connection-string\u0026#34;\rAZURE_CONTAINER_NAME = \u0026#34;your-container-name\u0026#34;\r# Khởi tạo Blob reader\rblob_reader = SimpleBlobReader(\rconnection_string=AZURE_CONNECTION_STRING,\rcontainer_name=AZURE_CONTAINER_NAME,\r)\r# Tải tài liệu trực tiếp từ Azure Blob Storage\rdocuments = blob_reader.load_data()\rprint(f\u0026#34;Loaded {len(documents)} documents from Azure Blob Storage!\u0026#34;) Cách hoạt động Xác thực: SimpleBlobReader sử dụng Azure connection string của bạn để xác thực với blob storage Truy xuất blob: SimpleBlobReader lấy và xử lý tất cả các blob từ container đã chỉ định Tương thích với LlamaIndex: Giống như S3 reader, SimpleBlobReader chuẩn bị tài liệu cho việc lập chỉ mục và truy vấn một cách liền mạch Phần 5: Nên chọn phương pháp nào Cách tiếp cận Phương pháp Tải thủ công Nếu bạn cần toàn quyền kiểm soát các tệp đã tải xuống hoặc làm việc offline sau khi truy xuất dữ liệu SimpleS3Reader Nếu bạn sử dụng S3 và muốn tích hợp trực tiếp mà không cần quản lý việc tải xuống tài liệu thủ công SimpleBlobReader Nếu bạn sử dụng Azure Blob Storage và cần tích hợp liền mạch để lập chỉ mục và truy vấn thời gian thực Ưu điểm của các readers tích hợp sẵn Hiệu quả: Tích hợp trực tiếp dịch vụ lưu trữ đám mây vào quy trình làm việc, giúp giảm bớt độ phức tạp Xử lý theo thời gian thực: Lý tưởng cho các tập dữ liệu động hoặc thường xuyên được cập nhật Hạn chế lặp code: Không cần dùng thêm các thư viện ngoài như boto3 hoặc azure-storage-blob, trừ khi bạn cần chức năng tùy chỉnh Phần 6: Ứng dụng thực tế Dưới đây là một số ví dụ ứng dụng thực tế cho Agent truy xuất thông tin của bạn:\nChatbots hỗ trợ khách hàng Huấn luyện Agent dựa trên sách hướng dẫn hoặc các câu hỏi thường gặp (FAQ) để cung cấp câu trả lời tức thì cho khách hàng. Trợ lý nghiên cứu Nạp thông tin các bài báo học thuật hoặc báo cáo, cho phép các nhà nghiên cứu dễ dàng truy xuất tóm tắt hoặc tài liệu tham khảo Quản lý thông tin trong doanh nghiệp Sử dụng Agent để tìm kiếm chính sách công ty, tài liệu nội bộ hoặc tài liệu đào tạo Triển khai Agent có thể đơn giản như đóng gói một ứng dụng Flask hoặc triển khai lên nền tảng serverless như AWS Lambda. Phần 7: Xử lý lỗi thường gặp và mẹo tối ưu Những lỗi thường gặp:\nLỗi bộ nhớ: Nếu bộ dữ liệu quá lớn, hãy dùng kỹ thuật chunking để chia tài liệu thành những phần nhỏ trước khi lập chỉ mục Kết quả không nhất quán: Thử nghiệm với các tham số như temperature và max_tokens để kiểm soát độ sáng tạo và độ dài đầu ra của mô hình Lỗi API: Đảm bảo API Keys chính xác và kiểm tra giới hạn tần suất đối với OpenAI và Hugging Face Mẹo tối ưu hóa: Truy vấn phân cấp: Dùng chỉ mục nâng cao cho các truy vấn nhiều tầng, ví dụ: tìm theo chủ đề trước, sau đó đi sâu vào chi tiết Gắn thẻ metadata: Gắn thẻ tài liệu với metadata (ví dụ: tác giả, ngày tháng) để cải thiện độ liên quan của truy vấn Phần 8: Kết luận Chúc mừng! Bạn vừa xây dựng một Agent truy xuất thông tin bằng LlamaIndex, OpenAI và Hugging Face. Bằng cách kết hợp các công cụ này, bạn đã tạo ra một hệ thống thông minh có khả năng truy vấn và truy xuất thông tin từ bất kỳ tập dữ liệu nào\nMọi khả năng ứng dụng là vô tận dù bạn xây dựng chatbot, trợ lý nghiên cứu hay công cụ doanh nghiệp, LlamaIndex cho phép bạn khai thác hiệu quả sức mạnh của các mô hình ngôn ngữ lớn.\nBạn đã sẵn sàng để tiến xa hơn chưa? Hãy thử nghiệm với các tập dữ liệu lớn hơn, mô hình tùy chỉnh trên Hugging Face hoặc các tính năng nâng cao của LlamaIndex. Tương lai của Agentic AI nằm trong tay bạn!\n📖 Glossary - Thuật ngữ English Tiếng Việt Định nghĩa Agent AI tự chủ Phần mềm dựa trên trí tuệ nhân tạo, có khả năng tự động thực hiện nhiệm vụ như trả lời câu hỏi, tìm kiếm thông tin, phân tích dữ liệu hoặc đưa ra quyết định. Khác với chatbot thụ động chỉ phản hồi khi được hỏi, Agent có thể chủ động hành động dựa trên mục tiêu đã được giao LLMs Ngôn ngữ lớn là các hệ thống trí tuệ nhân tạo (AI) tiên tiến được thiết kế để xử lý, hiểu và tạo văn bản giống con người index Chỉ mục là một cấu trúc dữ liệu được sử dụng trong các hệ quản trị cơ sở dữ liệu và các công cụ tìm kiếm để tăng tốc độ truy vấn và tìm kiếm thông tin dataset Bộ dữ liệu là tập hợp dữ liệu có tổ chức, đóng vai trò cốt lõi trong các lĩnh vực công nghệ như trí tuệ nhân tạo và học máy production Môi trường thực tế môi trường triển khai hệ thống để phục vụ người dùng cuối blob(Binary Large Object) Đối tượng nhị phân lớn là một kiểu dữ liệu trong cơ sở dữ liệu hoặc hệ thống lưu trữ, được dùng để chứa các dữ liệu nhị phân có kích thước lớn Embedding Biểu diễn vector biến dữ liệu (ví dụ văn bản, tài liệu) thành một dãy số (vector) mà máy tính có thể hiểu và so sánh Reader Là một class trong LlamaIndex Flask là một framework web viết bằng Python, được dùng để xây dựng các ứng dụng web hoặc API 🔗 Tài liệu tham khảo Tài liệu gốc Original Article: Bài viết gốc Author\u0026rsquo;s Profile: Thông tin tác giả Tài liệu tiếng Việt LlamaIndex: Tài liệu Llamaindex tiếng Việt S3 Azure Blob Storage Tools và Services LlamaIndex OpenAI Hugging Face Transformers S3 Azure Blob Storage 💬 Ghi chú của người dịch Challenges trong quá trình dịch Technical Terms: Cần giải thích rõ agent, embedding, LLMs để người đọc Việt Nam dễ hiểu. Cultural Context: Điều chỉnh phong cách diễn đạt, giữ tính chuyên ngành nhưng dễ tiếp cận. Complex Concepts: Các bước kỹ thuật cần viết mạch lạc, dễ hiểu. Insights gained Technical Learning: Biết cách tạo agent kết hợp LLM và dữ liệu đám mây. Language Skills: Tăng khả năng dịch các khái niệm AI sang tiếng Việt. Industry Knowledge: Thấy cách ứng dụng LLM trong hệ thống thực tế với AWS/Azure. 🤝 Đóng góp và Feedback Bài dịch này được thực hiện trong khuôn khổ FCJ Internship Program.\n📧 Liên hệ: [vinh021104@gmail.com]\n💬 Feedback: Mọi góp ý để cải thiện chất lượng dịch thuật xin gửi về email trên\n🔄 Updates: Bài dịch sẽ được cập nhật dựa trên feedback từ cộng đồng\n© 2025 - Bản dịch thuộc về Ngô THành Vinh. Vui lòng credit khi sử dụng.\n"
},
{
	"uri": "https://ntvinh04.github.io/blog-trans/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ntvinh04.github.io/blog-trans/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]